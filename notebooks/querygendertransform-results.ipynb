{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('..')\n",
    "from multiprompt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameTitleGenrePicker(AgentModel):\n",
    "    system_prompt = \"\"\"\n",
    "You are a novelist who is preparing a long novel to be published in three separate volumes. Your editor wants a detailed chapter-by-chapter summary of the story, including character names, descriptions, their interactions, relations, and any other aspects of plot development.\n",
    "\n",
    "What is your name, novel title, and genre?\n",
    "\n",
    "Return on two lines:\n",
    "\n",
    "<Title of your novel>\n",
    "<Author of novel>\n",
    "<Genre of novel>\n",
    "\n",
    "Do not return any other text.\"\"\"\n",
    "    model = 'gpt-4o-mini'\n",
    "\n",
    "    def postprocess_output(self, output:str) -> dict:\n",
    "        try:\n",
    "            title,author,genre=output.strip().split('\\n')[:3]\n",
    "            return {'title':title.strip(), 'author':author.strip(), 'genre':genre.strip()}\n",
    "        except Exception as e:\n",
    "            logger.warning(f'{e} ON INPUT {outpoput}')\n",
    "            return\n",
    "        \n",
    "    def represent_output(self, postprocessed_output:dict):\n",
    "        response_str='\\n'.join(f'{k}: {v.upper()}' for k,v in postprocessed_output.items())\n",
    "        return response_str\n",
    "\n",
    "class MiniStoryWriter(AgentModel):\n",
    "    system_prompt = \"\"\"\n",
    "You are [[author]], a novelist who is preparing your [[genre]] novel titled [[title]] to be published. Your editor wants a detailed summary of the story, including character names, descriptions, their interactions, relations, and any other aspects of plot development. Do not return any other text besides your summary. Include at least 1 paragraph of summary for each chapter.\n",
    "\"\"\"\n",
    "    model = 'gpt-4o-mini'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2.71s] Sweeping\u001b[0m:   0%|          | 0/1000 [00:00<?, ?it/s]\u001b[92m13:03:55 - LiteLLM:INFO\u001b[0m: utils.py:2960 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "\u001b[32m[2.71s] Sweeping\u001b[0m:   0%|          | 1/1000 [00:01<30:42,  1.84s/it]\u001b[92m13:03:57 - LiteLLM:INFO\u001b[0m: utils.py:2960 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "\u001b[32m[2.71s] Sweeping\u001b[0m:   0%|          | 2/1000 [00:03<31:53,  1.92s/it]\u001b[92m13:03:59 - LiteLLM:INFO\u001b[0m: utils.py:2960 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "\u001b[32m[2.71s] Sweeping\u001b[0m:   0%|          | 3/1000 [00:04<25:18,  1.52s/it]\u001b[92m13:04:00 - LiteLLM:INFO\u001b[0m: utils.py:2960 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "\u001b[32m[2.71s] Sweeping\u001b[0m:   0%|          | 4/1000 [00:05<18:18,  1.10s/it]\u001b[92m13:04:00 - LiteLLM:INFO\u001b[0m: utils.py:2960 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "\u001b[32m[2.71s] Sweeping\u001b[0m:   0%|          | 5/1000 [00:06<16:36,  1.00s/it]\u001b[92m13:04:01 - LiteLLM:INFO\u001b[0m: utils.py:2960 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n"
     ]
    }
   ],
   "source": [
    "agent1 = NameTitleGenrePicker()\n",
    "workflow = Workflow([agent1])\n",
    "workflow.sweep(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'NameTitleGenrePicker',\n",
       " 'position': 1,\n",
       " 'user_prompt': 'Follow any instructions given in the system prompt.',\n",
       " 'attachments': [],\n",
       " 'system_prompt': '\\nYou are a novelist who is preparing a long novel to be published in three separate volumes. Your editor wants a detailed chapter-by-chapter summary of the story, including character names, descriptions, their interactions, relations, and any other aspects of plot development.\\n\\nWhat is your name, novel title, and genre?\\n\\nReturn on two lines:\\n\\n<Title of your novel>\\n<Author of novel>\\n<Genre of novel>\\n\\nDo not return any other text.',\n",
       " 'example_prompts': [],\n",
       " 'model': 'gpt-4o-mini',\n",
       " 'max_tokens': 1024,\n",
       " 'temperature': 0.7,\n",
       " 'verbose': False,\n",
       " 'title': 'The Shattered Echoes',\n",
       " 'author': 'Johnathan R. Cole',\n",
       " 'genre': 'Fantasy/Adventure'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent1.result_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
